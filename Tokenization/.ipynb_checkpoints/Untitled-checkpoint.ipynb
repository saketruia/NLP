{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6eda2e3-06da-44fd-806d-ee3a6758f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db7d644-f223-4558-918e-f3ee2cc44116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr.\n",
      "Saket\n",
      "loves\n",
      "to\n",
      "have\n",
      "chole\n",
      "bhature\n",
      "of\n",
      "delhi\n",
      "whihc\n",
      "costs\n",
      "$\n",
      "5\n",
      "per\n",
      "plate\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "nlp=spacy.blank(\"en\")\n",
    "doc=nlp(\"Mr. Saket loves to have chole bhature of delhi whihc costs $5 per plate.\")\n",
    "for word in doc:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f17ef0d1-09fa-42e3-a2a7-3a4451664a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "city\n"
     ]
    }
   ],
   "source": [
    "doc1=nlp(\"Lets's go to N.Y. city\")\n",
    "for word in doc1:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7fc6cba-52c5-4b3e-a85d-c4ba2852534b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Saket"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2=nlp(\"Saket gave two $ to ayush\")\n",
    "token0=doc2[0]\n",
    "token0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f38d5614-51d6-4d63-9fc3-9c82f310481a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a17f56b-6b22-4d94-a08a-6b48fe835be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token0.is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70496305-6fee-4563-a3eb-8b17ce265e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token0.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d8c66cb-e609-4441-8170-13ebf339e4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "two"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2=doc2[2]\n",
    "token2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9bd7da-ee03-48c4-906b-a2b3468bd86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d510a037-363d-462c-94f9-3e244a39f8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token3=doc2[3]\n",
    "token3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6803561e-2d0a-4a4a-b2d5-be16f192d622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token3.is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50889eda-272e-47cd-ac28-e473fc6f148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saket ==> index:  0 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      "gave ==> index:  1 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      "two ==> index:  2 is_alpha: True is_punct: False like_num: True is_currency: False\n",
      "$ ==> index:  3 is_alpha: False is_punct: False like_num: False is_currency: True\n",
      "to ==> index:  4 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      "ayush ==> index:  5 is_alpha: True is_punct: False like_num: False is_currency: False\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token, \"==>\", \"index: \", token.i, \"is_alpha:\", token.is_alpha, \n",
    "          \"is_punct:\", token.is_punct, \n",
    "          \"like_num:\", token.like_num,\n",
    "          \"is_currency:\", token.is_currency,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbe8030c-bafb-452f-919a-3ef0117e7315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dayton high school, 8th grade students information\\n',\n",
       " '==================================================\\n',\n",
       " '\\n',\n",
       " 'Name\\tbirth day   \\temail\\n',\n",
       " '-----\\t------------\\t------\\n',\n",
       " 'Virat   5 June, 1882    virat@kohli.com\\n',\n",
       " 'Maria\\t12 April, 2001  maria@sharapova.com\\n',\n",
       " 'Serena  24 June, 1998   serena@williams.com \\n',\n",
       " 'Joe      1 May, 1997    joe@root.com\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"students.txt\") as f:\n",
    "          text=f.readlines()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39dcecff-3fd2-4b80-8e17-3c1859628e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dayton high school, 8th grade students information\\n ==================================================\\n \\n Name\\tbirth day   \\temail\\n -----\\t------------\\t------\\n Virat   5 June, 1882    virat@kohli.com\\n Maria\\t12 April, 2001  maria@sharapova.com\\n Serena  24 June, 1998   serena@williams.com \\n Joe      1 May, 1997    joe@root.com\\n \\n \\n \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=' '.join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e910ffb2-7558-4173-abbc-7447fa508d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virat@kohli.com',\n",
       " 'maria@sharapova.com',\n",
       " 'serena@williams.com',\n",
       " 'joe@root.com']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3=nlp(text)\n",
    "emails = []\n",
    "for token in doc3:\n",
    "    if token.like_email:\n",
    "        emails.append(token.text)\n",
    "emails     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41befe2d-ba54-416d-8f0a-7090d7a53ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "भैया\n",
      "जी\n",
      "!\n",
      "5000\n",
      "₹\n",
      "उधार\n",
      "थे\n",
      "वो\n",
      "वापस\n",
      "देदो\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"hi\")\n",
    "doc = nlp(\"भैया जी! 5000 ₹ उधार थे वो वापस देदो\")\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e235d40-a6d5-4edc-9148-ce86f5c66292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "भैया False\n",
      "जी False\n",
      "! False\n",
      "5000 False\n",
      "₹ True\n",
      "उधार False\n",
      "थे False\n",
      "वो False\n",
      "वापस False\n",
      "देदो False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.is_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4168b9bf-d57e-404f-99e1-91aa0cdaf33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54008c20-3916-47ab-a969-374415f20fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "897f6b66-c30a-49a4-8444-2bed1e33dd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.tokenizer.add_special_case(\"gimme\", [\n",
    "    {ORTH: \"gim\"},\n",
    "    {ORTH: \"me\"},\n",
    "])\n",
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2566bb9-645c-44c8-ae91-a15181dd5b58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msents\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\spacy\\tokens\\doc.pyx:926\u001b[0m, in \u001b[0;36msents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "677d6b9b-3b85-40f8-aa7d-239c2abc6025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "384e661f-d65f-4456-a51c-4487eeb7979e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x20a36e9aed0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bafbb95-8a37-4e2c-939b-c18a72c48d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Strange loves pav bhaji of mumbai.\n",
      "Hulk loves chat of delhi\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1aa2aa-9cd2-40a2-ae81-e1cb0f3e04aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (spacy)",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
